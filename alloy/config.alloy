///////////////////////////////////////////////////////////////////////////////
// Configuration file
local.file "endpoints" {
    // The endpoints file is used to define the endpoints, credentials and options
    // for the Alloy export to.
    filename = "/etc/alloy/endpoints.json"
}

///////////////////////////////////////////////////////////////////////////////
// Metrics scraping

// Scrape Mimir, Loki
// We use the prometheus.scrape component and give this a unique label.
prometheus.scrape "infra" {
    // The targets array allows us to specify which service targets to scrape from.
    // Define the address to scrape from, and add a 'group' and 'service' label for each target.
    targets = [
        {"__address__" = "mimir:9009", group = "infrastructure", service = "mimir"},
        {"__address__" = "loki:3100", group = "infrastructure", service = "loki"},
        {"__address__" = "grafana:3000", group = "infrastructure", service = "grafana"},
    ]

    // Scrape all of these services every 15 seconds.
    scrape_interval = "15s"
    // Send the metrics to the prometheus remote write receiver for exporting to Mimir.
    forward_to = [prometheus.remote_write.mimir.receiver]
    // The job name to add to the scraped metrics.
    job_name = "infra"
}

// // This component scrapes the Mythical application, defining unique prometheus labels.
// prometheus.scrape "mythical" {
//     // Scrape from the mythical requester and server services, and add them to the 'mythical' group with their service
//     // names.
//     targets = [
//         {"__address__" = "mythical-server:4000", group = "mythical", service = "mythical-server"},
//         {"__address__" = "mythical-requester:4001", group = "mythical", service = "mythical-requester"},
//     ]
//     // We need a scrape interval and timeout of 2s as we want reactive metric data.
//     scrape_interval = "2s"
//     scrape_timeout = "2s"
//     // Send the metrics to the prometheus remote write receiver for exporting to Mimir.
//     forward_to = [prometheus.remote_write.mimir.receiver]
//     // Attach the job name to the metrics.
//     job_name = "mythical"
// }

prometheus.scrape "docker" {
    targets = [
        {"__address__" = "cadvisor:8080", group = "infrastructure", service = "docker"},
    ]
    scrape_interval = "15s"
    forward_to = [prometheus.remote_write.mimir.receiver]
    job_name = "docker"
}

// Scrape the local Alloy itself.
prometheus.scrape "agent" {
    // Only one target, the Alloy, it's part of the 'infrastructure' group.
    targets = [{"__address__" = "localhost:12345", group = "infrastructure", service = "alloy"}]
    // Send the metrics to the prometheus remote write receiver for exporting to Mimir.
    forward_to = [prometheus.remote_write.mimir.receiver]
    // Attach job name to the metrics.
    job_name = "alloy"
}

// The Alloy exports everything, using an empty block.
prometheus.exporter.unix "default" {
}

// This component scrapes the Unix exporter metrics generated above.
prometheus.scrape "unix" {
    // Use the Unix prometheus exporter as the target.
    targets = prometheus.exporter.unix.default.targets
    // Send the metrics to the prometheus remote write receiver for exporting to Mimir.
    forward_to = [prometheus.remote_write.mimir.receiver]
    // Attach job name to the metrics.
    job_name = "node_exporter"
}

// The prometheus.remote_write component defines an endpoint for remotely writing metrics to.
// In this case, our locally running Mimir service.
prometheus.remote_write "mimir" {
    // The endpoint is the Mimir service.
    endpoint {
        url = json_path(local.file.endpoints.content, ".metrics.url")[0]

        // Basic auth credentials. If the endpoint is not TLS, whilst sent, these will be ignored.
        basic_auth {
            username = json_path(local.file.endpoints.content, ".metrics.basicAuth.username")[0]
            password = json_path(local.file.endpoints.content, ".metrics.basicAuth.password")[0]
        }
    }
}

///////////////////////////////////////////////////////////////////////////////
// Logging

// loki.source.api "mythical" {
//     http {
//         listen_address = "0.0.0.0"
//         listen_port = "3100"
//     }

//     forward_to = [loki.write.mythical.receiver]
// }

loki.write "loki" {
    // Output the Loki log to the local Loki instance.
    endpoint {
        url = json_path(local.file.endpoints.content, ".logs.url")[0]

        // The basic auth credentials for the Loki instance.
        basic_auth {
            username = json_path(local.file.endpoints.content, ".logs.basicAuth.username")[0]
            password = json_path(local.file.endpoints.content, ".logs.basicAuth.password")[0]
        }
    }
}
